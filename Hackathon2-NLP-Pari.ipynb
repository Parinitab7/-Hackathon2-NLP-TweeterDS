{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\91902\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\91902\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "from nltk import porter, lancaster,pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "from afinn import Afinn\n",
    "import pandas as pd\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import re\n",
    "#import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "#from sklearn.ensemble import RandomForestRegressor ,RandomForestClassifier\n",
    "from collections import Counter\n",
    "import emoji\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1701</td>\n",
       "      <td>#sxswnui #sxsw #apple defining language of tou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1851</td>\n",
       "      <td>Learning ab Google doodles! All doodles should...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2689</td>\n",
       "      <td>one of the most in-your-face ex. of stealing t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4525</td>\n",
       "      <td>This iPhone #SXSW app would b pretty awesome i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3604</td>\n",
       "      <td>Line outside the Apple store in Austin waiting...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id                                              tweet  sentiment\n",
       "0      1701  #sxswnui #sxsw #apple defining language of tou...          1\n",
       "1      1851  Learning ab Google doodles! All doodles should...          1\n",
       "2      2689  one of the most in-your-face ex. of stealing t...          2\n",
       "3      4525  This iPhone #SXSW app would b pretty awesome i...          0\n",
       "4      3604  Line outside the Apple store in Austin waiting...          1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4311\n",
       "2    2382\n",
       "0     456\n",
       "3     125\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7274"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #Removing null row from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id     0\n",
       "tweet        1\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7274, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id     0\n",
       "tweet        0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7273, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7255"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Performing basic preprocessing under tweetprocessing()\n",
    "\n",
    "Lowercase\n",
    "\n",
    "Punctuation Removal\n",
    "\n",
    "Emoji detection and removal\n",
    "\n",
    "Non ASCII characters detection and removal\n",
    "\n",
    "Unique token stemming words\n",
    "\n",
    "Basic stopwords removal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweetprocessing(df):\n",
    "    \n",
    "    def extract_emojis(str):\n",
    "        str = ''.join(c for c in str if c in emoji.UNICODE_EMOJI)\n",
    "        return str\n",
    "\n",
    "    def replace_emoji(str):\n",
    "        str = ''.join(i for i in str if not i in extract_emojis(str))\n",
    "        return str\n",
    "    \n",
    "    def extract_nonascii(str):\n",
    "        str = ''.join(c for c in str if  ord(c) > 128)\n",
    "        return str\n",
    "\n",
    "\n",
    "    def replace_nonascii(str):\n",
    "        str = ''.join(i for i in str if not i in extract_nonascii(str))\n",
    "        return str\n",
    "    \n",
    "    def get_unique_tokens_lower_stem(text):\n",
    "        unique_tokens_lower_stem = set([ps.stem(w) for w in word_tokenize(text)])\n",
    "        return ' '.join(unique_tokens_lower_stem)\n",
    "    \n",
    "    def get_stopwords(text):\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        total_stopwords = set([w for w in word_tokenize(text) if w not in stop_words])\n",
    "        return ' '.join(total_stopwords)\n",
    "    \n",
    "    \"__________________________Convert to Lower Case____________________________________\"\n",
    "    df['tweet'] = df['tweet'].str.lower()\n",
    "    \n",
    "    \"__________________________Remove Punctuations______________________________________\"\n",
    "    \n",
    "    df['tweet'] = df['tweet'].str.replace('[^\\w\\s]','')\n",
    "    \n",
    "    \"__________________________Remove Emoji_____________________________________________\"\n",
    "    df['tweet'] = df['tweet'].apply(lambda x: replace_emoji(x))\n",
    "    \n",
    "    \n",
    "    \"__________________________Remove non ASCII_________________________________________\"\n",
    "      \n",
    "    df['tweet'] = df['tweet'].apply(lambda x: replace_nonascii(x))\n",
    "    \n",
    "    \n",
    "    \"__________________________Get unique tokens with stemming__________________________\"\n",
    "    df['unique_tokens_lower_stem'] = df['tweet'].apply(lambda x :get_unique_tokens_lower_stem(x))\n",
    "    \n",
    "    \n",
    "            \n",
    "    \"__________________Remove basic stopwords and get unique words from tweet____________\"\n",
    "    df['no_stopwords'] = df['unique_tokens_lower_stem'].apply(lambda x :get_stopwords(x) )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = tweetprocessing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>unique_tokens_lower_stem</th>\n",
       "      <th>no_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1701</td>\n",
       "      <td>sxswnui sxsw apple defining language of touch ...</td>\n",
       "      <td>1</td>\n",
       "      <td>defin differ touch dialect appl smaller becom ...</td>\n",
       "      <td>defin touch sxswnui dialect appl smaller becom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1851</td>\n",
       "      <td>learning ab google doodles all doodles should ...</td>\n",
       "      <td>1</td>\n",
       "      <td>sxsw all googledoodl learn for occas except si...</td>\n",
       "      <td>googledoodl ab learn light except signific fun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2689</td>\n",
       "      <td>one of the most inyourface ex of stealing the ...</td>\n",
       "      <td>2</td>\n",
       "      <td>inyourfac most school mention yr the appl expe...</td>\n",
       "      <td>sxsw inyourfac school rt mention yr appl exper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4525</td>\n",
       "      <td>this iphone sxsw app would b pretty awesome if...</td>\n",
       "      <td>0</td>\n",
       "      <td>brows illmakeitwork everi it iphon awesom didn...</td>\n",
       "      <td>brows awesom extend thi didnt illmakeitwork b ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3604</td>\n",
       "      <td>line outside the apple store in austin waiting...</td>\n",
       "      <td>1</td>\n",
       "      <td>line austin ipad wait the for outsid appl link...</td>\n",
       "      <td>line austin ipad wait outsid appl link store n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id                                              tweet  sentiment  \\\n",
       "0      1701  sxswnui sxsw apple defining language of touch ...          1   \n",
       "1      1851  learning ab google doodles all doodles should ...          1   \n",
       "2      2689  one of the most inyourface ex of stealing the ...          2   \n",
       "3      4525  this iphone sxsw app would b pretty awesome if...          0   \n",
       "4      3604  line outside the apple store in austin waiting...          1   \n",
       "\n",
       "                            unique_tokens_lower_stem  \\\n",
       "0  defin differ touch dialect appl smaller becom ...   \n",
       "1  sxsw all googledoodl learn for occas except si...   \n",
       "2  inyourfac most school mention yr the appl expe...   \n",
       "3  brows illmakeitwork everi it iphon awesom didn...   \n",
       "4  line austin ipad wait the for outsid appl link...   \n",
       "\n",
       "                                        no_stopwords  \n",
       "0  defin touch sxswnui dialect appl smaller becom...  \n",
       "1  googledoodl ab learn light except signific fun...  \n",
       "2  sxsw inyourfac school rt mention yr appl exper...  \n",
       "3  brows awesom extend thi didnt illmakeitwork b ...  \n",
       "4  line austin ipad wait outsid appl link store n...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Creating sentiment scorewise dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentimentwise_df(df):\n",
    "    \n",
    "    df0 = df[df['sentiment']==0]\n",
    "    df1 = df[df['sentiment']==1]\n",
    "    df2 = df[df['sentiment']==2]\n",
    "    df3 = df[df['sentiment']==3]\n",
    "    return df0,df1,df2,df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0,df1,df2,df3 = get_sentimentwise_df(newdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>unique_tokens_lower_stem</th>\n",
       "      <th>no_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4525</td>\n",
       "      <td>this iphone sxsw app would b pretty awesome if...</td>\n",
       "      <td>0</td>\n",
       "      <td>brows illmakeitwork everi it iphon awesom didn...</td>\n",
       "      <td>brows awesom extend thi didnt illmakeitwork b ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>634</td>\n",
       "      <td>mention i have a 3g iphone after 3 hrs tweetin...</td>\n",
       "      <td>0</td>\n",
       "      <td>mention wa dead it station have hr 3 upgrad ip...</td>\n",
       "      <td>sxsw hr mention tweet dead plugin station 3g r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1178</td>\n",
       "      <td>so i went the whole day wout my laptop amp jus...</td>\n",
       "      <td>0</td>\n",
       "      <td>whole cloudapp laptop ftp so i ipad the my wen...</td>\n",
       "      <td>day miss ipad went whole 1 thing use skype clo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>5058</td>\n",
       "      <td>rt mention google lost its way by caring too m...</td>\n",
       "      <td>0</td>\n",
       "      <td>much rt lost the mention care user psych busi ...</td>\n",
       "      <td>much rt lost mention care psych busi googl vs ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2435</td>\n",
       "      <td>i composed a tweet so acerbic and cynical abou...</td>\n",
       "      <td>0</td>\n",
       "      <td>twitterpow phone so i ipad imthatgood that use...</td>\n",
       "      <td>sxsw acerb ipad twitterpow imthatgood tweet du...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tweet_id                                              tweet  sentiment  \\\n",
       "3       4525  this iphone sxsw app would b pretty awesome if...          0   \n",
       "24       634  mention i have a 3g iphone after 3 hrs tweetin...          0   \n",
       "34      1178  so i went the whole day wout my laptop amp jus...          0   \n",
       "50      5058  rt mention google lost its way by caring too m...          0   \n",
       "63      2435  i composed a tweet so acerbic and cynical abou...          0   \n",
       "\n",
       "                             unique_tokens_lower_stem  \\\n",
       "3   brows illmakeitwork everi it iphon awesom didn...   \n",
       "24  mention wa dead it station have hr 3 upgrad ip...   \n",
       "34  whole cloudapp laptop ftp so i ipad the my wen...   \n",
       "50  much rt lost the mention care user psych busi ...   \n",
       "63  twitterpow phone so i ipad imthatgood that use...   \n",
       "\n",
       "                                         no_stopwords  \n",
       "3   brows awesom extend thi didnt illmakeitwork b ...  \n",
       "24  sxsw hr mention tweet dead plugin station 3g r...  \n",
       "34  day miss ipad went whole 1 thing use skype clo...  \n",
       "50  much rt lost mention care psych busi googl vs ...  \n",
       "63  sxsw acerb ipad twitterpow imthatgood tweet du...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>unique_tokens_lower_stem</th>\n",
       "      <th>no_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1701</td>\n",
       "      <td>sxswnui sxsw apple defining language of touch ...</td>\n",
       "      <td>1</td>\n",
       "      <td>defin differ touch dialect appl smaller becom ...</td>\n",
       "      <td>defin touch sxswnui dialect appl smaller becom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1851</td>\n",
       "      <td>learning ab google doodles all doodles should ...</td>\n",
       "      <td>1</td>\n",
       "      <td>sxsw all googledoodl learn for occas except si...</td>\n",
       "      <td>googledoodl ab learn light except signific fun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3604</td>\n",
       "      <td>line outside the apple store in austin waiting...</td>\n",
       "      <td>1</td>\n",
       "      <td>line austin ipad wait the for outsid appl link...</td>\n",
       "      <td>line austin ipad wait outsid appl link store n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>966</td>\n",
       "      <td>technews one lone dude awaits ipad 2 at apples...</td>\n",
       "      <td>1</td>\n",
       "      <td>ipad ipad_2 tablet tech_new dude await appl 2 ...</td>\n",
       "      <td>ipad ipad_2 tablet lone tech_new dude await ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1395</td>\n",
       "      <td>sxsw tips prince npr videos toy shopping with ...</td>\n",
       "      <td>1</td>\n",
       "      <td>princ ipad tip zuckerberg toy link with video ...</td>\n",
       "      <td>ipad princ tip zuckerberg toy link video sxsw ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id                                              tweet  sentiment  \\\n",
       "0      1701  sxswnui sxsw apple defining language of touch ...          1   \n",
       "1      1851  learning ab google doodles all doodles should ...          1   \n",
       "4      3604  line outside the apple store in austin waiting...          1   \n",
       "5       966  technews one lone dude awaits ipad 2 at apples...          1   \n",
       "6      1395  sxsw tips prince npr videos toy shopping with ...          1   \n",
       "\n",
       "                            unique_tokens_lower_stem  \\\n",
       "0  defin differ touch dialect appl smaller becom ...   \n",
       "1  sxsw all googledoodl learn for occas except si...   \n",
       "4  line austin ipad wait the for outsid appl link...   \n",
       "5  ipad ipad_2 tablet tech_new dude await appl 2 ...   \n",
       "6  princ ipad tip zuckerberg toy link with video ...   \n",
       "\n",
       "                                        no_stopwords  \n",
       "0  defin touch sxswnui dialect appl smaller becom...  \n",
       "1  googledoodl ab learn light except signific fun...  \n",
       "4  line austin ipad wait outsid appl link store n...  \n",
       "5  ipad ipad_2 tablet lone tech_new dude await ap...  \n",
       "6  ipad princ tip zuckerberg toy link video sxsw ...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>unique_tokens_lower_stem</th>\n",
       "      <th>no_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2689</td>\n",
       "      <td>one of the most inyourface ex of stealing the ...</td>\n",
       "      <td>2</td>\n",
       "      <td>inyourfac most school mention yr the appl expe...</td>\n",
       "      <td>sxsw inyourfac school rt mention yr appl exper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8835</td>\n",
       "      <td>free sxsw sampler on itunes link freemusic</td>\n",
       "      <td>2</td>\n",
       "      <td>freemus on sampler free link sxsw itun</td>\n",
       "      <td>freemus sampler link free sxsw itun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>883</td>\n",
       "      <td>i think i might go all weekend without seeing ...</td>\n",
       "      <td>2</td>\n",
       "      <td>i all ipad might weekend the case twice same t...</td>\n",
       "      <td>ipad case might weekend twice think go see wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2369</td>\n",
       "      <td>its official im buying an ipad sxsw elevate</td>\n",
       "      <td>2</td>\n",
       "      <td>im an ipad it offici buy sxsw elev</td>\n",
       "      <td>im ipad offici buy sxsw elev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3944</td>\n",
       "      <td>theyre giving away ipad 2s x boxes and books a...</td>\n",
       "      <td>2</td>\n",
       "      <td>2s ipad and box x mention book theyr away give...</td>\n",
       "      <td>2s ipad mention box x book theyr away give tec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tweet_id                                              tweet  sentiment  \\\n",
       "2       2689  one of the most inyourface ex of stealing the ...          2   \n",
       "8       8835         free sxsw sampler on itunes link freemusic          2   \n",
       "9        883  i think i might go all weekend without seeing ...          2   \n",
       "11      2369        its official im buying an ipad sxsw elevate          2   \n",
       "12      3944  theyre giving away ipad 2s x boxes and books a...          2   \n",
       "\n",
       "                             unique_tokens_lower_stem  \\\n",
       "2   inyourfac most school mention yr the appl expe...   \n",
       "8              freemus on sampler free link sxsw itun   \n",
       "9   i all ipad might weekend the case twice same t...   \n",
       "11                 im an ipad it offici buy sxsw elev   \n",
       "12  2s ipad and box x mention book theyr away give...   \n",
       "\n",
       "                                         no_stopwords  \n",
       "2   sxsw inyourfac school rt mention yr appl exper...  \n",
       "8                 freemus sampler link free sxsw itun  \n",
       "9   ipad case might weekend twice think go see wit...  \n",
       "11                       im ipad offici buy sxsw elev  \n",
       "12  2s ipad mention box x book theyr away give tec...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>unique_tokens_lower_stem</th>\n",
       "      <th>no_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6398</td>\n",
       "      <td>rt mention official sxsw app sxsw go bitlyhmii...</td>\n",
       "      <td>3</td>\n",
       "      <td>rt ipad mention go offici android bitlyhmiiga ...</td>\n",
       "      <td>rt ipad mention go offici android bitlyhmiiga ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5368</td>\n",
       "      <td>standing on a long line surrounded by unemploy...</td>\n",
       "      <td>3</td>\n",
       "      <td>am i ipad the appl or a line 5th on techi ave ...</td>\n",
       "      <td>line 5th ipad wait techi appl brooklyn long st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>4618</td>\n",
       "      <td>googlebing search smackdown panel is in a gian...</td>\n",
       "      <td>3</td>\n",
       "      <td>room panel have giant googleb hope a you is fo...</td>\n",
       "      <td>giant googleb chair room quotfloorsittingquot ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>7469</td>\n",
       "      <td>original products for 1 device is nuts sxsw eg...</td>\n",
       "      <td>3</td>\n",
       "      <td>ipad eg devic the origin 1 is nut for product ...</td>\n",
       "      <td>ipad eg devic origin 1 nut product sxsw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>2116</td>\n",
       "      <td>iphone crashed in front of sxsw apple popup be...</td>\n",
       "      <td>3</td>\n",
       "      <td>popup front crash appl in bestworstthingev of ...</td>\n",
       "      <td>popup crash front appl bestworstthingev sxsw i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id                                              tweet  sentiment  \\\n",
       "10       6398  rt mention official sxsw app sxsw go bitlyhmii...          3   \n",
       "28       5368  standing on a long line surrounded by unemploy...          3   \n",
       "123      4618  googlebing search smackdown panel is in a gian...          3   \n",
       "133      7469  original products for 1 device is nuts sxsw eg...          3   \n",
       "242      2116  iphone crashed in front of sxsw apple popup be...          3   \n",
       "\n",
       "                              unique_tokens_lower_stem  \\\n",
       "10   rt ipad mention go offici android bitlyhmiiga ...   \n",
       "28   am i ipad the appl or a line 5th on techi ave ...   \n",
       "123  room panel have giant googleb hope a you is fo...   \n",
       "133  ipad eg devic the origin 1 is nut for product ...   \n",
       "242  popup front crash appl in bestworstthingev of ...   \n",
       "\n",
       "                                          no_stopwords  \n",
       "10   rt ipad mention go offici android bitlyhmiiga ...  \n",
       "28   line 5th ipad wait techi appl brooklyn long st...  \n",
       "123  giant googleb chair room quotfloorsittingquot ...  \n",
       "133            ipad eg devic origin 1 nut product sxsw  \n",
       "242  popup crash front appl bestworstthingev sxsw i...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
